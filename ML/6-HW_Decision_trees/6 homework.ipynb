{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к занятию 2.1: Деревья решений. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор прошедшего занятия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы делали в классе:\n",
    "\n",
    "**Задание 1**\n",
    "* строили деревья\n",
    "* критерии информативности которых написали даже сами\n",
    "* визуализировали границы принятия решений в 2d\n",
    "* и рисовали сами деревья\n",
    "\n",
    "\n",
    "**Задание 2**\n",
    "* приняли участие в соревновании на Kaggle, переварив кучу текстовых фичей в численные, проведя кросс-валидацию и сделав сабмит\n",
    "\n",
    "\n",
    "**Задание 3**\n",
    "* построили руками несколько метрик качества бинарной классификации\n",
    "\n",
    "\n",
    "**Задание 4**\n",
    "* использовали их для оценки классификации разделения статей Ведомостей по топикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*дополнительно было много приятных ништяков. Например, облако слов, мультипоточность в целях парсинга, удобный инструмент для нахождения правильной css разметки, сохранение моделей в статичные файлы, разделение строк на слова и лемматизация этих слов*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lvl 1:**\n",
    "\n",
    "* взять подготовленные раннее данные из задачи **Titanic**, обучиться на них с помощью дерева решений и кросс-валидации и сделать сабмит\n",
    "* кросс-валидацию желательно сделать сразу по нескольким фичам ( параметр *grid* в *GridSearchCV* )\n",
    "* определить самые важные фичи\n",
    "* вывести дерево решений (можете попробовать установить pydot и webgraphviz для отрисовки деревьев внутри ноутбука)\n",
    "\n",
    "**Результат:** скрины нового сабмита на Kaggle и построенного дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lvl 2:** (опционально)\n",
    "\n",
    "* С помощью функций sklearn.metrics.auc, precision, recall составить функцию для расчёта ROC-AUC, ROC-PRC\n",
    "* Придумать себе интересную задачу на основе данных из интернета =) Спарсить ещё какой-нибудь сайт (не Ведомости) и решить задачу классификации. Делать свои проекты - круто. Если будут - кидайте мне =) [@NikitaKuznetsov](http://t.me/NikitaKuznesov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "train = pd.read_csv('titanic/train.csv')\n",
    "test = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "y_train = train.Survived\n",
    "train.drop('Survived', axis=1, inplace=True)\n",
    "\n",
    "train['is_test'] = 0\n",
    "test['is_test'] = 1\n",
    "\n",
    "df = pd.concat([train, test])\n",
    "\n",
    "df[\"isMale\"] = df.Sex.replace({\"male\": 1, \"female\":0})\n",
    "df.drop([\"Sex\", \"Cabin\", \"Ticket\", \"Name\", \"PassengerId\"], axis=1, inplace=True)\n",
    "\n",
    "df_dummies = pd.get_dummies(df, columns=['Pclass', 'Embarked'])\n",
    "\n",
    "X_train = df_dummies[df_dummies.is_test==0].drop('is_test', axis=1)\n",
    "X_test = df_dummies[df_dummies.is_test==1].drop('is_test', axis=1)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=True)\n",
    "imputer.fit(X_train)\n",
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=columns)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_imputed)\n",
    "X_train_imputed_scaled = scaler.transform(X_train_imputed)\n",
    "X_train_imputed_scaled = pd.DataFrame(X_train_imputed_scaled, columns=columns)\n",
    "\n",
    "X_test_imputed_scaled = scaler.transform(imputer.transform(X_test))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "ppl = pca.fit_transform(X_train_imputed_scaled)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 7\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "kmeans.fit(X_train_imputed_scaled)\n",
    "\n",
    "cluster_labels = kmeans.predict(X_train_imputed_scaled)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_fin, X_val, y_train_fin, y_val = train_test_split(X_train_imputed_scaled, y_train, test_size=0.2)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cs = 10**np.linspace(-3,1,5)\n",
    "cs\n",
    "\n",
    "grid = {'C': cs}\n",
    "gridsearch = GridSearchCV(LogisticRegression(), grid, scoring='accuracy', cv=5)\n",
    "gridsearch.fit(X_train_fin, y_train_fin)\n",
    "\n",
    "sorted(gridsearch.grid_scores_, key = lambda x: -x.mean_validation_score)\n",
    "\n",
    "best_C = gridsearch.best_params_[\"C\"]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression(C=best_C)\n",
    "clf.fit(X_train_fin, y_train_fin)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "# accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_imputed_scaled, y_train)\n",
    "clf.predict_proba(X_test_imputed_scaled)[:10]\n",
    "predictions = clf.predict(X_test_imputed_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
